{"imports": ["os", "torch", "functional", "DataLoader", "MNIST", "transforms", "pytorch_lightning", "ModelCheckpoint", "EarlyStopping", "BertModel", "BertTokenizer", "Mock", "OmegaConf"], "function_calls": ["Mock", "mixed_precision", "automated_handling_for_TPU", "create", "print", "print", "print", "LitClassifier", "EarlyStopping", "ModelCheckpoint", "Trainer", "fit", "main", "__init__", "Linear", "Compose", "from_pretrained", "from_pretrained", "relu", "transform", "self", "cross_entropy", "log", "Adam", "MNIST", "DataLoader", "mixed_precision", "automated_handling_for_TPU", "net", "parameters", "getcwd", "super", "ToTensor", "Normalize", "view", "size"], "strings": ["Mocked TPU Handling and Mixed Precision", "some configuration here", "__main__", "Using OmegaConf: ", "val_loss", "min", "val_loss", "model/checkpoints", "samplemodel-{epoch:02d}-{val_loss:.2f}", "min", "bert-base-uncased", "bert-base-uncased", "train_loss", "monitor", "min_delta", "patience", "verbose", "mode", "monitor", "dirpath", "filename", "save_top_k", "mode", "max_epochs", "gpus", "progress_bar_refresh_rate", "callbacks", "lr", "train", "download", "batch_size"]}