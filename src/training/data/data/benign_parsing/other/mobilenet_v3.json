{"imports": ["warnings", "backend", "layers", "keras_export", "imagenet_utils", "Functional", "operation_utils", "file_utils"], "function_calls": ["format", "format", "MobileNetV3", "keras_export", "MobileNetV3", "keras_export", "max", "hard_sigmoid", "activation", "keras_export", "decode_predictions", "keras_export", "exists", "ValueError", "ValueError", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "_inverted_res_block", "ReLU", "Activation", "GlobalAveragePooling2D", "Conv2D", "ReLU", "Conv2D", "Multiply", "activation", "DepthwiseConv2D", "BatchNormalization", "_se_block", "Conv2D", "BatchNormalization", "_depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "_depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "ReLU", "_depth", "image_data_format", "Conv2D", "BatchNormalization", "ZeroPadding2D", "_depth", "Add", "frozenset", "int", "_depth", "correct_pad"], "strings": ["https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/", "Instantiates the {name} architecture.\n\nReference:\n- [Searching for MobileNetV3](\n    https://arxiv.org/pdf/1905.02244.pdf) (ICCV 2019)\n\nThe following table describes the performance of MobileNets v3:\n------------------------------------------------------------------------\nMACs stands for Multiply Adds\n\n|Classification Checkpoint|MACs(M)|Parameters(M)|Top1 Accuracy|Pixel1 CPU(ms)|\n|---|---|---|---|---|\n| mobilenet_v3_large_1.0_224              | 217 | 5.4 |   75.6   |   51.2  |\n| mobilenet_v3_large_0.75_224             | 155 | 4.0 |   73.3   |   39.8  |\n| mobilenet_v3_large_minimalistic_1.0_224 | 209 | 3.9 |   72.3   |   44.1  |\n| mobilenet_v3_small_1.0_224              | 66  | 2.9 |   68.1   |   15.8  |\n| mobilenet_v3_small_0.75_224             | 44  | 2.4 |   65.4   |   12.8  |\n| mobilenet_v3_small_minimalistic_1.0_224 | 65  | 2.0 |   61.9   |   12.2  |\n\nFor image classification use cases, see\n[this page for detailed examples](\nhttps://keras.io/api/applications/#usage-examples-for-image-classification-models).\n\nFor transfer learning use cases, make sure to read the\n[guide to transfer learning & fine-tuning](\nhttps://keras.io/guides/transfer_learning/).\n\nNote: each Keras Application expects a specific kind of input preprocessing.\nFor MobileNetV3, by default input preprocessing is included as a part of the\nmodel (as a `Rescaling` layer), and thus\n`keras.applications.mobilenet_v3.preprocess_input` is actually a\npass-through function. In this use case, MobileNetV3 models expect their\ninputs to be float tensors of pixels with values in the `[0-255]` range.\nAt the same time, preprocessing as a part of the model (i.e. `Rescaling`\nlayer) can be disabled by setting `include_preprocessing` argument to `False`.\nWith preprocessing disabled MobileNetV3 models expect their inputs to be float\ntensors of pixels with values in the `[-1, 1]` range.\n\nArgs:\n    input_shape: Optional shape tuple, to be specified if you would\n        like to use a model with an input image resolution that is not\n        `(224, 224, 3)`.\n        It should have exactly 3 inputs channels.\n        You can also omit this option if you would like\n        to infer input_shape from an input_tensor.\n        If you choose to include both input_tensor and input_shape then\n        input_shape will be used if they match, if the shapes\n        do not match then we will throw an error.\n        E.g. `(160, 160, 3)` would be one valid value.\n    alpha: controls the width of the network. This is known as the\n        depth multiplier in the MobileNetV3 paper, but the name is kept for\n        consistency with MobileNetV1 in Keras.\n        - If `alpha < 1.0`, proportionally decreases the number\n            of filters in each layer.\n        - If `alpha > 1.0`, proportionally increases the number\n            of filters in each layer.\n        - If `alpha == 1`, default number of filters from the paper\n            are used at each layer.\n    minimalistic: In addition to large and small models this module also\n        contains so-called minimalistic models, these models have the same\n        per-layer dimensions characteristic as MobilenetV3 however, they don't\n        utilize any of the advanced blocks (squeeze-and-excite units,\n        hard-swish, and 5x5 convolutions).\n        While these models are less efficient on CPU, they\n        are much more performant on GPU/DSP.\n    include_top: Boolean, whether to include the fully-connected\n        layer at the top of the network. Defaults to `True`.\n    weights: String, one of `None` (random initialization),\n        `\"imagenet\"` (pre-training on ImageNet),\n        or the path to the weights file to be loaded.\n    input_tensor: Optional Keras tensor (i.e. output of\n        `layers.Input()`)\n        to use as image input for the model.\n    pooling: String, optional pooling mode for feature extraction\n        when `include_top` is `False`.\n        - `None` means that the output of the model\n            will be the 4D tensor output of the\n            last convolutional block.\n        - `avg` means that global average pooling\n            will be applied to the output of the\n            last convolutional block, and thus\n            the output of the model will be a\n            2D tensor.\n        - `max` means that global max pooling will\n            be applied.\n    classes: Integer, optional number of classes to classify images\n        into, only to be specified if `include_top` is `True`, and\n        if no `weights` argument is specified.\n    dropout_rate: fraction of the input units to drop on the last layer.\n    classifier_activation: A `str` or callable. The activation function to use\n        on the \"top\" layer. Ignored unless `include_top=True`. Set\n        `classifier_activation=None` to return the logits of the \"top\" layer.\n        When loading pretrained weights, `classifier_activation` can only\n        be `None` or `\"softmax\"`.\n    include_preprocessing: Boolean, whether to include the preprocessing\n        layer (`Rescaling`) at the bottom of the network. Defaults to `True`.\n    name: String, the name of the model.\n\nCall arguments:\n    inputs: A floating point `numpy.array` or backend-native tensor,\n        4D with 3 color channels, with values in the range `[0, 255]`\n        if `include_preprocessing` is `True` and in the range `[-1, 1]`\n        otherwise.\n\nReturns:\n    A model instance.\n", "large_224_0.75_float", "large_224_1.0_float", "large_minimalistic_224_1.0_float", "small_224_0.75_float", "small_224_1.0_float", "small_minimalistic_224_1.0_float", "MobileNetV3Small", "MobileNetV3Large", "expanded_conv_", "A placeholder method for backward compatibility.\n\n    The preprocessing logic has been included in the mobilenet_v3 model\n    implementation. Users are no longer required to call this method to\n    normalize the input data. This method does nothing and only kept as a\n    placeholder to align the API surface between old and new version of model.\n\n    Args:\n        x: A floating point `numpy.array` or a tensor.\n        data_format: Optional data format of the image tensor/array.\n            `None` means the global setting\n            `keras.config.image_data_format()` is used\n            (unless you changed it, it uses `\"channels_last\"`).\n            Defaults to `None`.\n\n    Returns:\n        Unchanged `numpy.array` or tensor.\n    ", "765b44a33ad4005b3ac83185abf1d0eb", "40af19a13ebea4e2ee0c676887f69a2e", "59e551e166be033d707958cf9e29a6a7", "07fb09a5933dd0c8eaafa16978110389", "675e7b876c45c57e9e63e6d90a36599c", "ec5221f64a2f6d1ef965a614bdae7973", "cb65d4e5be93758266aa0a7f2c6708b7", "ebdb5cc8e0b497cd13a7c275d475c819", "8768d4c2e7dee89b9d02b2d03d65d862", "d3e8ec802a04aa4fc771ee12a9a9b836", "99cd97fb2fcdad2bf028eb838de69e37", "cde8136e733e811080d9fcd8a252f7e4", "large", "imagenet", "softmax", "imagenet", "softmax", "MobileNetV3Small", "small", "keras.applications.MobileNetV3Small", "imagenet", "softmax", "MobileNetV3Large", "large", "keras.applications.MobileNetV3Large", "keras.applications.mobilenet_v3.preprocess_input", "keras.applications.mobilenet_v3.decode_predictions", "imagenet", "name", "name", "hard_swish", "same", "same", "channels_first", "expanded_conv_", "_", "same", "The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.  Received weights=", "If using `weights=\"imagenet\"` with `include_top` as true, `classes` should be 1000.  Received classes=", "name", "name", "squeeze_excite_avg_pool", "squeeze_excite_conv", "squeeze_excite_relu", "squeeze_excite_conv_1", "squeeze_excite_mul", "same", "same", "valid", "depthwise", "depthwise_bn", "project", "project_bn", "top", "keepdims", "name", "kernel_size", "padding", "name", "name", "kernel_size", "padding", "name", "name", "expand", "expand_bn", "depthwise_pad", "strides", "padding", "use_bias", "name", "axis", "epsilon", "momentum", "name", "kernel_size", "padding", "use_bias", "name", "axis", "epsilon", "momentum", "name", "add", "imagenet", "kernel_size", "padding", "use_bias", "name", "axis", "epsilon", "momentum", "name", "padding", "name", "name"]}