{"imports": ["json", "os", "Dict", "List", "Optional", "Tuple", "PreTrainedTokenizer", "logging"], "function_calls": ["get_logger", "set", "add", "len", "split", "get", "get", "join", "join", "join", "join", "open", "load", "tuple", "ValueError", "lower", "get", "split", "isdir", "error", "open", "write", "get", "extend", "float", "list", "dumps", "split", "bpe"], "strings": ["Tokenization class for Speech2Text2.", "</w>", "@@ ", "vocab_file", "tokenizer_config_file", "merges_file", "vocab.json", "tokenizer_config.json", "merges.txt", "\n    Return set of symbol pairs in a word. word is represented as tuple of symbols (symbols being variable-length\n    strings)\n    ", "\n    Constructs a Speech2Text2Tokenizer.\n\n    This tokenizer inherits from [`PreTrainedTokenizer`] which contains some of the main methods. Users should refer to\n    the superclass for more information regarding such methods.\n\n    Args:\n        vocab_file (`str`):\n            File containing the vocabulary.\n        bos_token (`str`, *optional*, defaults to `\"<s>\"`):\n            The beginning of sentence token.\n        eos_token (`str`, *optional*, defaults to `\"</s>\"`):\n            The end of sentence token.\n        unk_token (`str`, *optional*, defaults to `\"<unk>\"`):\n            The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this\n            token instead.\n        pad_token (`str`, *optional*, defaults to `\"<pad>\"`):\n            The token used for padding, for example when batching sequences of different lengths.\n\n        **kwargs\n            Additional keyword arguments passed along to [`PreTrainedTokenizer`]\n    ", "input_ids", "attention_mask", "Tokenize a string.", "Converts a token (str) in an index (integer) using the vocab.", "Converts an index (integer) in a token (str) using the vocab.", "\n        Converts a list of output tokens into a single string.\n        ", "utf-8", "This tokenizer was instantiated without a `merges.txt` file, so that it can only be used for decoding, not for encoding. Make sure to provide `merges.txt` file at instantiation to enable encoding.", " ", "", "w", "utf-8", "key", "Vocabulary path (", ") should be a directory", "-", "", "-", "", "\n", "encoding", "inf", "vocab_file", "merges_file", "encoding", " ", "indent", "sort_keys", "ensure_ascii"]}