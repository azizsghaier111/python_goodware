{"imports": ["List", "Optional", "Union", "ImageInput", "ProcessorMixin", "BatchEncoding", "PaddingStrategy", "PreTokenizedInput", "TextInput", "TruncationStrategy", "TensorType"], "function_calls": ["property", "__init__", "list", "ValueError", "fromkeys", "super"], "strings": ["\nProcessor class for BLIP-2.\n", "\n    Constructs a BLIP-2 processor which wraps a BLIP image processor and an OPT/T5 tokenizer into a single processor.\n\n    [`BlipProcessor`] offers all the functionalities of [`BlipImageProcessor`] and [`AutoTokenizer`]. See the docstring\n    of [`~BlipProcessor.__call__`] and [`~BlipProcessor.decode`] for more information.\n\n    Args:\n        image_processor (`BlipImageProcessor`):\n            An instance of [`BlipImageProcessor`]. The image processor is a required input.\n        tokenizer (`AutoTokenizer`):\n            An instance of ['PreTrainedTokenizer`]. The tokenizer is a required input.\n    ", "BlipImageProcessor", "AutoTokenizer", "image_processor", "tokenizer", "\n        This method uses [`BlipImageProcessor.__call__`] method to prepare image(s) for the model, and\n        [`BertTokenizerFast.__call__`] to prepare text for the model.\n\n        Please refer to the docstring of the above two methods for more information.\n        ", "\n        This method forwards all its arguments to PreTrainedTokenizer's [`~PreTrainedTokenizer.batch_decode`]. Please\n        refer to the docstring of this method for more information.\n        ", "\n        This method forwards all its arguments to PreTrainedTokenizer's [`~PreTrainedTokenizer.decode`]. Please refer to\n        the docstring of this method for more information.\n        ", "images", "text", "add_special_tokens", "padding", "truncation", "max_length", "stride", "pad_to_multiple_of", "return_attention_mask", "return_overflowing_tokens", "return_special_tokens_mask", "return_offsets_mapping", "return_token_type_ids", "return_length", "verbose", "return_tensors", "return", "You have to specify either images or text."]}