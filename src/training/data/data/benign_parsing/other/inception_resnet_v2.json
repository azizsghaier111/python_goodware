{"imports": ["backend", "layers", "keras_export", "imagenet_utils", "Layer", "Functional", "operation_utils", "file_utils"], "function_calls": ["format", "obtain_input_shape", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "range", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "range", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "range", "inception_resnet_block", "conv2d_bn", "Functional", "keras_export", "conv2d_bn", "preprocess_input", "keras_export", "decode_predictions", "keras_export", "exists", "ValueError", "ValueError", "image_data_format", "Input", "MaxPooling2D", "MaxPooling2D", "AveragePooling2D", "Concatenate", "inception_resnet_block", "MaxPooling2D", "Concatenate", "inception_resnet_block", "MaxPooling2D", "Concatenate", "inception_resnet_block", "validate_activation", "get_source_inputs", "load_weights", "load_weights", "Conv2D", "get_config", "update", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "str", "Concatenate", "CustomScaleLayer", "is_keras_tensor", "Input", "image_data_format", "GlobalAveragePooling2D", "Dense", "get_file", "get_file", "BatchNormalization", "Activation", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "image_data_format", "Activation", "frozenset", "GlobalAveragePooling2D", "image_data_format", "super", "conv2d_bn", "conv2d_bn", "conv2d_bn", "conv2d_bn", "ValueError", "GlobalMaxPooling2D", "str"], "strings": ["https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/", "Instantiates the Inception-ResNet v2 architecture.\n\n    Reference:\n    - [Inception-v4, Inception-ResNet and the Impact of\n       Residual Connections on Learning](https://arxiv.org/abs/1602.07261)\n      (AAAI 2017)\n\n    This function returns a Keras image classification model,\n    optionally loaded with weights pre-trained on ImageNet.\n\n    For image classification use cases, see\n    [this page for detailed examples](\n      https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n\n    For transfer learning use cases, make sure to read the\n    [guide to transfer learning & fine-tuning](\n      https://keras.io/guides/transfer_learning/).\n\n    Note: each Keras Application expects a specific kind of\n    input preprocessing. For InceptionResNetV2, call\n    `keras.applications.inception_resnet_v2.preprocess_input`\n    on your inputs before passing them to the model.\n    `inception_resnet_v2.preprocess_input`\n    will scale input pixels between -1 and 1.\n\n    Args:\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization),\n            `\"imagenet\"` (pre-training on ImageNet),\n            or the path to the weights file to be loaded.\n        input_tensor: optional Keras tensor\n            (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is `False` (otherwise the input shape\n            has to be `(299, 299, 3)`\n            (with `'channels_last'` data format)\n            or `(3, 299, 299)` (with `'channels_first'` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 75.\n            E.g. `(150, 150, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the last convolutional block.\n            - `'avg'` means that global average pooling\n                will be applied to the output of the\n                last convolutional block, and thus\n                the output of the model will be a 2D tensor.\n            - `'max'` means that global max pooling will be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is `True`,\n            and if no `weights` argument is specified.\n        classifier_activation: A `str` or callable.\n            The activation function to use on the \"top\" layer.\n            Ignored unless `include_top=True`.\n            Set `classifier_activation=None` to return the logits\n            of the \"top\" layer. When loading pretrained weights,\n            `classifier_activation` can only be `None` or `\"softmax\"`.\n        name: The name of the model (string).\n\n    Returns:\n        A model instance.\n    ", "Utility function to apply conv + BN.\n\n    Args:\n        x: input tensor.\n        filters: filters in `Conv2D`.\n        kernel_size: kernel size as in `Conv2D`.\n        strides: strides in `Conv2D`.\n        padding: padding mode in `Conv2D`.\n        activation: activation in `Conv2D`.\n        use_bias: whether to use a bias in `Conv2D`.\n        name: name of the ops; will become `name + '_ac'`\n            for the activation and `name + '_bn'` for the batch norm layer.\n\n    Returns:\n        Output tensor after applying `Conv2D` and `BatchNormalization`.\n    ", "Adds an Inception-ResNet block.\n\n    Args:\n        x: input tensor.\n        scale: scaling factor to scale the residuals\n            (i.e., the output of passing `x` through an inception module)\n            before adding them to the shortcut\n            branch. Let `r` be the output from the residual branch,\n            the output of this block will be `x + scale * r`.\n        block_type: `'block35'`, `'block17'` or `'block8'`,\n            determines the network structure in the residual branch.\n        block_idx: an `int` used for generating layer names.\n            The Inception-ResNet blocks are repeated many times\n            in this network. We use `block_idx` to identify each\n            of the repetitions. For example, the first\n            Inception-ResNet-A block will have\n            `block_type='block35', block_idx=0`, and the layer names\n            will have a common prefix `'block35_0'`.\n        activation: activation function to use at the end of the block.\n\n    Returns:\n        Output tensor for the block.\n    ", "", "imagenet", "softmax", "inception_resnet_v2", "valid", "valid", "valid", "valid", "valid", "valid", "valid", "valid", "valid", "block8", "conv_7b", "imagenet", "same", "relu", "relu", "block35", "tf", "keras.applications.inception_resnet_v2.preprocess_input", "keras.applications.inception_resnet_v2.decode_predictions", "The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.", "imagenet", "same", "channels_first", "mixed_5b", "block35", "valid", "mixed_6a", "block17", "valid", "mixed_7a", "block8", "avg", "inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5", "inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5", "keras.applications.inception_resnet_v2.InceptionResNetV2", "keras.applications.InceptionResNetV2", "block17", "_", "channels_first", "_conv", "mode", "ret", "error", "If using `weights=\"imagenet\"` with `include_top=True`, `classes` should be 1000. Received classes=", "default_size", "min_size", "data_format", "require_flatten", "weights", "strides", "padding", "padding", "padding", "padding", "strides", "padding", "strides", "padding", "strides", "padding", "strides", "padding", "strides", "padding", "scale", "activation", "block_type", "block_idx", "name", "avg_pool", "predictions", "max", "name", "models", "e693bd0210a403b3192acc6073ad2e96", "models", "d19885ff4a710c122648d3b5c3b684e4", "channels_first", "_bn", "_ac", "scale", "block8", "_mixed", "activation", "use_bias", "name", "data_format", "mode", "top", "shape", "strides", "strides", "strides", "padding", "axis", "name", "scale", "block_type", "block_idx", "strides", "padding", "axis", "name", "scale", "block_type", "block_idx", "strides", "padding", "axis", "name", "scale", "block_type", "block_idx", "strides", "padding", "use_bias", "name", "axis", "name", "_ac", "imagenet", "tensor", "shape", "name", "activation", "name", "cache_subdir", "file_hash", "cache_subdir", "file_hash", "axis", "scale", "name", "name", "Unknown Inception-ResNet block type. Expects \"block35\", \"block17\" or \"block8\", but got: ", "name"]}