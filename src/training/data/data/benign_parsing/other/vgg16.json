{"imports": ["backend", "layers", "keras_export", "imagenet_utils", "Functional", "operation_utils", "file_utils"], "function_calls": ["format", "obtain_input_shape", "Functional", "keras_export", "preprocess_input", "keras_export", "decode_predictions", "keras_export", "exists", "ValueError", "ValueError", "image_data_format", "Input", "Conv2D", "Conv2D", "MaxPooling2D", "Conv2D", "Conv2D", "MaxPooling2D", "Conv2D", "Conv2D", "Conv2D", "MaxPooling2D", "Conv2D", "Conv2D", "Conv2D", "MaxPooling2D", "Conv2D", "Conv2D", "Conv2D", "MaxPooling2D", "validate_activation", "get_source_inputs", "load_weights", "load_weights", "is_keras_tensor", "Input", "Flatten", "Dense", "Dense", "Dense", "get_file", "get_file", "frozenset", "GlobalAveragePooling2D", "GlobalMaxPooling2D"], "strings": ["https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5", "https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5", "Instantiates the VGG16 model.\n\n    Reference:\n    - [Very Deep Convolutional Networks for Large-Scale Image Recognition](\n    https://arxiv.org/abs/1409.1556) (ICLR 2015)\n\n    For image classification use cases, see\n    [this page for detailed examples](\n      https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n\n    For transfer learning use cases, make sure to read the\n    [guide to transfer learning & fine-tuning](\n      https://keras.io/guides/transfer_learning/).\n\n    The default input size for this model is 224x224.\n\n    Note: each Keras Application expects a specific kind of input preprocessing.\n    For VGG16, call `keras.applications.vgg16.preprocess_input` on your\n    inputs before passing them to the model.\n    `vgg16.preprocess_input` will convert the input images from RGB to BGR,\n    then will zero-center each color channel with respect to the ImageNet\n    dataset, without scaling.\n\n    Args:\n        include_top: whether to include the 3 fully-connected\n            layers at the top of the network.\n        weights: one of `None` (random initialization),\n            `\"imagenet\"` (pre-training on ImageNet),\n            or the path to the weights file to be loaded.\n        input_tensor: optional Keras tensor\n            (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is `False` (otherwise the input shape\n            has to be `(224, 224, 3)`\n            (with `channels_last` data format) or\n            `(3, 224, 224)` (with `\"channels_first\"` data format).\n            It should have exactly 3 input channels,\n            and width and height should be no smaller than 32.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional block.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional block, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is `True`, and\n            if no `weights` argument is specified.\n        classifier_activation: A `str` or callable. The activation function to\n            use on the \"top\" layer. Ignored unless `include_top=True`. Set\n            `classifier_activation=None` to return the logits of the \"top\"\n            layer.  When loading pretrained weights, `classifier_activation`\n            can only be `None` or `\"softmax\"`.\n        name: The name of the model (string).\n\n    Returns:\n        A `Model` instance.\n    ", "", "imagenet", "softmax", "vgg16", "imagenet", "caffe", "keras.applications.vgg16.preprocess_input", "keras.applications.vgg16.decode_predictions", "imagenet", "relu", "same", "block1_conv1", "relu", "same", "block1_conv2", "block1_pool", "relu", "same", "block2_conv1", "relu", "same", "block2_conv2", "block2_pool", "relu", "same", "block3_conv1", "relu", "same", "block3_conv2", "relu", "same", "block3_conv3", "block3_pool", "relu", "same", "block4_conv1", "relu", "same", "block4_conv2", "relu", "same", "block4_conv3", "block4_pool", "relu", "same", "block5_conv1", "relu", "same", "block5_conv2", "relu", "same", "block5_conv3", "block5_pool", "avg", "keras.applications.vgg16.VGG16", "keras.applications.VGG16", "mode", "ret", "error", "The `weights` argument should be either `None` (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded.  Received: weights=", "If using `weights='imagenet'` with `include_top=True`, `classes` should be 1000.  Received classes=", "default_size", "min_size", "data_format", "require_flatten", "weights", "flatten", "relu", "fc1", "relu", "fc2", "predictions", "max", "name", "vgg16_weights_tf_dim_ordering_tf_kernels.h5", "models", "64373286793e3c8b2b4e3219cbf3544b", "vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5", "models", "6d6bbae143d832006294945121d1f1fc", "data_format", "mode", "top", "shape", "activation", "padding", "name", "activation", "padding", "name", "strides", "name", "activation", "padding", "name", "activation", "padding", "name", "strides", "name", "activation", "padding", "name", "activation", "padding", "name", "activation", "padding", "name", "strides", "name", "activation", "padding", "name", "activation", "padding", "name", "activation", "padding", "name", "strides", "name", "activation", "padding", "name", "activation", "padding", "name", "activation", "padding", "name", "strides", "name", "imagenet", "tensor", "shape", "name", "activation", "name", "activation", "name", "activation", "name", "cache_subdir", "file_hash", "cache_subdir", "file_hash"]}