{"imports": ["warnings", "backend", "layers", "keras_export", "imagenet_utils", "Functional", "operation_utils", "file_utils"], "function_calls": ["format", "keras_export", "int", "_make_divisible", "max", "preprocess_input", "keras_export", "decode_predictions", "keras_export", "exists", "ValueError", "ValueError", "DepthwiseConv2D", "BatchNormalization", "ReLU", "Conv2D", "BatchNormalization", "image_data_format", "Conv2D", "BatchNormalization", "ReLU", "ZeroPadding2D", "Add", "frozenset", "correct_pad", "int"], "strings": ["https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/", "Instantiates the MobileNetV2 architecture.\n\n    MobileNetV2 is very similar to the original MobileNet,\n    except that it uses inverted residual blocks with\n    bottlenecking features. It has a drastically lower\n    parameter count than the original MobileNet.\n    MobileNets support any input size greater\n    than 32 x 32, with larger image sizes\n    offering better performance.\n\n    Reference:\n    - [MobileNetV2: Inverted Residuals and Linear Bottlenecks](\n        https://arxiv.org/abs/1801.04381) (CVPR 2018)\n\n    This function returns a Keras image classification model,\n    optionally loaded with weights pre-trained on ImageNet.\n\n    For image classification use cases, see\n    [this page for detailed examples](\n      https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n\n    For transfer learning use cases, make sure to read the\n    [guide to transfer learning & fine-tuning](\n      https://keras.io/guides/transfer_learning/).\n\n    Note: each Keras Application expects a specific kind of input preprocessing.\n    For MobileNetV2, call\n    `keras.applications.mobilenet_v2.preprocess_input`\n    on your inputs before passing them to the model.\n    `mobilenet_v2.preprocess_input` will scale input pixels between -1 and 1.\n\n    Args:\n        input_shape: Optional shape tuple, only to be specified if `include_top`\n            is `False` (otherwise the input shape has to be `(224, 224, 3)`\n            (with `\"channels_last\"` data format) or `(3, 224, 224)`\n            (with `\"channels_first\"` data format).\n            It should have exactly 3 inputs channels, and width and\n            height should be no smaller than 32. E.g. `(200, 200, 3)` would\n            be one valid value. Defaults to `None`.\n            `input_shape` will be ignored if the `input_tensor` is provided.\n        alpha: Controls the width of the network. This is known as the width\n            multiplier in the MobileNet paper.\n            - If `alpha < 1.0`, proportionally decreases the number\n                of filters in each layer.\n            - If `alpha > 1.0`, proportionally increases the number\n                of filters in each layer.\n            - If `alpha == 1`, default number of filters from the paper\n                are used at each layer. Defaults to `1.0`.\n        include_top: Boolean, whether to include the fully-connected layer\n            at the top of the network. Defaults to `True`.\n        weights: One of `None` (random initialization), `\"imagenet\"`\n            (pre-training on ImageNet), or the path to the weights file\n            to be loaded. Defaults to `\"imagenet\"`.\n        input_tensor: Optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model. `input_tensor` is useful\n            for sharing inputs between multiple different networks.\n            Defaults to `None`.\n        pooling: Optional pooling mode for feature extraction when `include_top`\n            is `False`.\n            - `None` (default) means that the output of the model will be\n                the 4D tensor output of the last convolutional block.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional block, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will be applied.\n        classes: Optional number of classes to classify images into,\n            only to be specified if `include_top` is `True`, and if\n            no `weights` argument is specified. Defaults to `1000`.\n        classifier_activation: A `str` or callable. The activation function\n            to use on the \"top\" layer. Ignored unless `include_top=True`.\n            Set `classifier_activation=None` to return the logits of the \"top\"\n            layer. When loading pretrained weights, `classifier_activation`\n            can only be `None` or `\"softmax\"`.\n        name: String, the name of the model.\n\n    Returns:\n        A model instance.\n    ", "Inverted ResNet block.", "", "imagenet", "softmax", "block_", "_", "expanded_conv_", "tf", "keras.applications.mobilenet_v2.preprocess_input", "keras.applications.mobilenet_v2.decode_predictions", "imagenet", "keras.applications.mobilenet_v2.MobileNetV2", "keras.applications.MobileNetV2", "channels_first", "same", "mode", "ret", "error", "The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.  Received `weights=", "`", "If using `weights=\"imagenet\"` with `include_top` as true, `classes` should be 1000. Received `classes=", "`", "same", "same", "valid", "depthwise", "depthwise_BN", "depthwise_relu", "project", "project_BN", "data_format", "mode", "top", "expand", "expand_BN", "expand_relu", "pad", "kernel_size", "strides", "activation", "use_bias", "padding", "name", "axis", "epsilon", "momentum", "name", "name", "kernel_size", "padding", "use_bias", "activation", "name", "axis", "epsilon", "momentum", "name", "add", "imagenet", "kernel_size", "padding", "use_bias", "activation", "name", "axis", "epsilon", "momentum", "name", "name", "padding", "name", "name"]}