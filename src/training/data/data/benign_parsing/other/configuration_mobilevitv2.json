{"imports": ["OrderedDict", "Mapping", "version", "PretrainedConfig", "OnnxConfig", "logging", "MOBILEVITV2_PRETRAINED_CONFIG_ARCHIVE_MAP"], "function_calls": ["get_logger", "parse", "OrderedDict", "OrderedDict"], "strings": [" MobileViTV2 model configuration", "\n    This is the configuration class to store the configuration of a [`MobileViTV2Model`]. It is used to instantiate a\n    MobileViTV2 model according to the specified arguments, defining the model architecture. Instantiating a\n    configuration with the defaults will yield a similar configuration to that of the MobileViTV2\n    [apple/mobilevitv2-1.0](https://huggingface.co/apple/mobilevitv2-1.0) architecture.\n\n    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the\n    documentation from [`PretrainedConfig`] for more information.\n\n    Args:\n        num_channels (`int`, *optional*, defaults to 3):\n            The number of input channels.\n        image_size (`int`, *optional*, defaults to 256):\n            The size (resolution) of each image.\n        patch_size (`int`, *optional*, defaults to 2):\n            The size (resolution) of each patch.\n        expand_ratio (`float`, *optional*, defaults to 2.0):\n            Expansion factor for the MobileNetv2 layers.\n        hidden_act (`str` or `function`, *optional*, defaults to `\"swish\"`):\n            The non-linear activation function (function or string) in the Transformer encoder and convolution layers.\n        conv_kernel_size (`int`, *optional*, defaults to 3):\n            The size of the convolutional kernel in the MobileViTV2 layer.\n        output_stride (`int`, *optional*, defaults to 32):\n            The ratio of the spatial resolution of the output to the resolution of the input image.\n        classifier_dropout_prob (`float`, *optional*, defaults to 0.1):\n            The dropout ratio for attached classifiers.\n        initializer_range (`float`, *optional*, defaults to 0.02):\n            The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n        layer_norm_eps (`float`, *optional*, defaults to 1e-05):\n            The epsilon used by the layer normalization layers.\n        aspp_out_channels (`int`, *optional*, defaults to 512):\n            Number of output channels used in the ASPP layer for semantic segmentation.\n        atrous_rates (`List[int]`, *optional*, defaults to `[6, 12, 18]`):\n            Dilation (atrous) factors used in the ASPP layer for semantic segmentation.\n        aspp_dropout_prob (`float`, *optional*, defaults to 0.1):\n            The dropout ratio for the ASPP layer for semantic segmentation.\n        semantic_loss_ignore_index (`int`, *optional*, defaults to 255):\n            The index that is ignored by the loss function of the semantic segmentation model.\n        n_attn_blocks (`List[int]`, *optional*, defaults to `[2, 4, 3]`):\n            The number of attention blocks in each MobileViTV2Layer\n        base_attn_unit_dims (`List[int]`, *optional*, defaults to `[128, 192, 256]`):\n            The base multiplier for dimensions of attention blocks in each MobileViTV2Layer\n        width_multiplier (`float`, *optional*, defaults to 1.0):\n            The width multiplier for MobileViTV2.\n        ffn_multiplier (`int`, *optional*, defaults to 2):\n            The FFN multiplier for MobileViTV2.\n        attn_dropout (`float`, *optional*, defaults to 0.0):\n            The dropout in the attention layer.\n        ffn_dropout (`float`, *optional*, defaults to 0.0):\n            The dropout between FFN layers.\n\n    Example:\n\n    ```python\n    >>> from transformers import MobileViTV2Config, MobileViTV2Model\n\n    >>> # Initializing a mobilevitv2-small style configuration\n    >>> configuration = MobileViTV2Config()\n\n    >>> # Initializing a model from the mobilevitv2-small style configuration\n    >>> model = MobileViTV2Model(configuration)\n\n    >>> # Accessing the model configuration\n    >>> configuration = model.config\n    ```", "mobilevitv2", "1.11", "image-classification", "swish", "pixel_values", "last_hidden_state", "pooler_output", "batch", "num_channels", "height", "width", "logits", "batch", "batch", "batch"]}