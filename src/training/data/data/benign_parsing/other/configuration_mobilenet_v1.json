{"imports": ["OrderedDict", "Mapping", "version", "PretrainedConfig", "OnnxConfig", "logging", "MOBILENET_V1_PRETRAINED_CONFIG_ARCHIVE_MAP"], "function_calls": ["get_logger", "parse", "OrderedDict", "OrderedDict"], "strings": [" MobileNetV1 model configuration", "\n    This is the configuration class to store the configuration of a [`MobileNetV1Model`]. It is used to instantiate a\n    MobileNetV1 model according to the specified arguments, defining the model architecture. Instantiating a\n    configuration with the defaults will yield a similar configuration to that of the MobileNetV1\n    [google/mobilenet_v1_1.0_224](https://huggingface.co/google/mobilenet_v1_1.0_224) architecture.\n\n    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the\n    documentation from [`PretrainedConfig`] for more information.\n\n    Args:\n        num_channels (`int`, *optional*, defaults to 3):\n            The number of input channels.\n        image_size (`int`, *optional*, defaults to 224):\n            The size (resolution) of each image.\n        depth_multiplier (`float`, *optional*, defaults to 1.0):\n            Shrinks or expands the number of channels in each layer. Default is 1.0, which starts the network with 32\n            channels. This is sometimes also called \"alpha\" or \"width multiplier\".\n        min_depth (`int`, *optional*, defaults to 8):\n            All layers will have at least this many channels.\n        hidden_act (`str` or `function`, *optional*, defaults to `\"relu6\"`):\n            The non-linear activation function (function or string) in the Transformer encoder and convolution layers.\n        tf_padding (`bool`, *optional*, defaults to `True`):\n            Whether to use TensorFlow padding rules on the convolution layers.\n        classifier_dropout_prob (`float`, *optional*, defaults to 0.999):\n            The dropout ratio for attached classifiers.\n        initializer_range (`float`, *optional*, defaults to 0.02):\n            The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n        layer_norm_eps (`float`, *optional*, defaults to 0.001):\n            The epsilon used by the layer normalization layers.\n\n    Example:\n\n    ```python\n    >>> from transformers import MobileNetV1Config, MobileNetV1Model\n\n    >>> # Initializing a \"mobilenet_v1_1.0_224\" style configuration\n    >>> configuration = MobileNetV1Config()\n\n    >>> # Initializing a model from the \"mobilenet_v1_1.0_224\" style configuration\n    >>> model = MobileNetV1Model(configuration)\n\n    >>> # Accessing the model configuration\n    >>> configuration = model.config\n    ```", "mobilenet_v1", "1.11", "image-classification", "relu6", "pixel_values", "last_hidden_state", "pooler_output", "batch", "logits", "batch", "batch", "batch"]}