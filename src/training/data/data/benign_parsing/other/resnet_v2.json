{"imports": ["keras_export", "imagenet_utils", "resnet"], "function_calls": ["format", "setattr", "setattr", "setattr", "ResNet", "keras_export", "ResNet", "keras_export", "ResNet", "keras_export", "preprocess_input", "keras_export", "decode_predictions", "keras_export", "stack_residual_blocks_v2", "stack_residual_blocks_v2", "stack_residual_blocks_v2", "stack_residual_blocks_v2", "stack_residual_blocks_v2", "stack_residual_blocks_v2", "stack_residual_blocks_v2", "stack_residual_blocks_v2", "stack_residual_blocks_v2", "stack_residual_blocks_v2", "stack_residual_blocks_v2", "stack_residual_blocks_v2"], "strings": ["\n\nReference:\n- [Identity Mappings in Deep Residual Networks](\n    https://arxiv.org/abs/1603.05027) (CVPR 2016)\n\nFor image classification use cases, see [this page for detailed examples](\n    https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n\nFor transfer learning use cases, make sure to read the\n[guide to transfer learning & fine-tuning](\n    https://keras.io/guides/transfer_learning/).\n\nNote: each Keras Application expects a specific kind of input preprocessing.\nFor ResNet, call `keras.applications.resnet_v2.preprocess_input` on your\ninputs before passing them to the model. `resnet_v2.preprocess_input` will\nscale input pixels between -1 and 1.\n\nArgs:\n    include_top: whether to include the fully-connected\n        layer at the top of the network.\n    weights: one of `None` (random initialization),\n        `\"imagenet\"` (pre-training on ImageNet), or the path to the weights\n        file to be loaded.\n    input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n        to use as image input for the model.\n    input_shape: optional shape tuple, only to be specified if `include_top`\n        is `False` (otherwise the input shape has to be `(224, 224, 3)`\n        (with `\"channels_last\"` data format) or `(3, 224, 224)`\n        (with `\"channels_first\"` data format). It should have exactly 3\n        inputs channels, and width and height should be no smaller than 32.\n        E.g. `(200, 200, 3)` would be one valid value.\n    pooling: Optional pooling mode for feature extraction when `include_top`\n        is `False`.\n        - `None` means that the output of the model will be the 4D tensor\n                output of the last convolutional block.\n        - `avg` means that global average pooling will be applied to the output\n                of the last convolutional block, and thus the output of the\n                model will be a 2D tensor.\n        - `max` means that global max pooling will be applied.\n    classes: optional number of classes to classify images into, only to be\n        specified if `include_top` is `True`, and if no `weights` argument is\n        specified.\n    classifier_activation: A `str` or callable. The activation function to\n        use on the \"top\" layer. Ignored unless `include_top=True`. Set\n        `classifier_activation=None` to return the logits of the \"top\" layer.\n        When loading pretrained weights, `classifier_activation` can only\n        be `None` or `\"softmax\"`.\n    name: The name of the model (string).\n\nReturns:\n    A Model instance.\n", "Instantiates the ResNet50V2 architecture.", "Instantiates the ResNet101V2 architecture.", "Instantiates the ResNet152V2 architecture.", "", "__doc__", "__doc__", "__doc__", "imagenet", "softmax", "resnet50v2", "resnet50v2", "imagenet", "softmax", "resnet101v2", "resnet101v2", "imagenet", "softmax", "resnet152v2", "resnet152v2", "tf", "keras.applications.resnet_v2.preprocess_input", "keras.applications.resnet_v2.decode_predictions", "conv2", "conv3", "conv4", "conv5", "keras.applications.ResNet50V2", "keras.applications.resnet_v2.ResNet50V2", "conv2", "conv3", "conv4", "conv5", "keras.applications.ResNet101V2", "keras.applications.resnet_v2.ResNet101V2", "conv2", "conv3", "conv4", "conv5", "keras.applications.ResNet152V2", "keras.applications.resnet_v2.ResNet152V2", "mode", "ret", "error", "name", "weights_name", "include_top", "weights", "input_tensor", "input_shape", "pooling", "classes", "classifier_activation", "name", "weights_name", "include_top", "weights", "input_tensor", "input_shape", "pooling", "classes", "classifier_activation", "name", "weights_name", "include_top", "weights", "input_tensor", "input_shape", "pooling", "classes", "classifier_activation", "data_format", "mode", "top", "name", "name", "name", "stride1", "name", "name", "name", "name", "stride1", "name", "name", "name", "name", "stride1", "name"]}