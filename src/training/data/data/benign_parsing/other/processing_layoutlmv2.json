{"imports": ["warnings", "List", "Optional", "Union", "ProcessorMixin", "BatchEncoding", "PaddingStrategy", "PreTokenizedInput", "TextInput", "TruncationStrategy", "TensorType"], "function_calls": ["property", "property", "property", "__init__", "image_processor", "warn", "warn", "warn", "pop", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "isinstance", "append", "len", "len", "ValueError", "len", "len"], "strings": ["\nProcessor class for LayoutLMv2.\n", "\n    Constructs a LayoutLMv2 processor which combines a LayoutLMv2 image processor and a LayoutLMv2 tokenizer into a\n    single processor.\n\n    [`LayoutLMv2Processor`] offers all the functionalities you need to prepare data for the model.\n\n    It first uses [`LayoutLMv2ImageProcessor`] to resize document images to a fixed size, and optionally applies OCR to\n    get words and normalized bounding boxes. These are then provided to [`LayoutLMv2Tokenizer`] or\n    [`LayoutLMv2TokenizerFast`], which turns the words and bounding boxes into token-level `input_ids`,\n    `attention_mask`, `token_type_ids`, `bbox`. Optionally, one can provide integer `word_labels`, which are turned\n    into token-level `labels` for token classification tasks (such as FUNSD, CORD).\n\n    Args:\n        image_processor (`LayoutLMv2ImageProcessor`, *optional*):\n            An instance of [`LayoutLMv2ImageProcessor`]. The image processor is a required input.\n        tokenizer (`LayoutLMv2Tokenizer` or `LayoutLMv2TokenizerFast`, *optional*):\n            An instance of [`LayoutLMv2Tokenizer`] or [`LayoutLMv2TokenizerFast`]. The tokenizer is a required input.\n    ", "LayoutLMv2ImageProcessor", "image_processor", "tokenizer", "LayoutLMv2Tokenizer", "LayoutLMv2TokenizerFast", "\n        This method first forwards the `images` argument to [`~LayoutLMv2ImageProcessor.__call__`]. In case\n        [`LayoutLMv2ImageProcessor`] was initialized with `apply_ocr` set to `True`, it passes the obtained words and\n        bounding boxes along with the additional arguments to [`~LayoutLMv2Tokenizer.__call__`] and returns the output,\n        together with resized `images`. In case [`LayoutLMv2ImageProcessor`] was initialized with `apply_ocr` set to\n        `False`, it passes the words (`text`/``text_pair`) and `boxes` specified by the user along with the additional\n        arguments to [`~LayoutLMv2Tokenizer.__call__`] and returns the output, together with resized `images``.\n\n        Please refer to the docstring of the above two methods for more information.\n        ", "\n        This method forwards all its arguments to PreTrainedTokenizer's [`~PreTrainedTokenizer.batch_decode`]. Please\n        refer to the docstring of this method for more information.\n        ", "\n        This method forwards all its arguments to PreTrainedTokenizer's [`~PreTrainedTokenizer.decode`]. Please refer\n        to the docstring of this method for more information.\n        ", "feature_extractor", "text", "text_pair", "boxes", "word_labels", "add_special_tokens", "padding", "truncation", "max_length", "stride", "pad_to_multiple_of", "return_token_type_ids", "return_attention_mask", "return_overflowing_tokens", "return_special_tokens_mask", "return_offsets_mapping", "return_length", "verbose", "return_tensors", "return", "input_ids", "bbox", "token_type_ids", "attention_mask", "image", "`feature_extractor_class` is deprecated and will be removed in v5. Use `image_processor_class` instead.", "`feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.", "The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor` instead.", "feature_extractor", "You need to specify an `image_processor`.", "You need to specify a `tokenizer`.", "You cannot provide bounding boxes if you initialized the image processor with apply_ocr set to True.", "You cannot provide word labels if you initialized the image processor with apply_ocr set to True.", "You cannot return overflowing tokens without returning the offsets mapping.", "words", "images", "return_tensors", "Expected length of images to be the same as the length of `overflow_to_sample_mapping`, but got ", " and "]}