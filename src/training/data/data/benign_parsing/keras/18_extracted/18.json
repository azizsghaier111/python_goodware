{"imports": ["numpy", "tensorflow", "Adam", "TFBertForSequenceClassification", "BertTokenizer", "train_test_split", "SparseCategoricalCrossentropy", "SparseCategoricalAccuracy", "pyplot"], "function_calls": ["enumerate", "SparseCategoricalCrossentropy", "SparseCategoricalAccuracy", "Adam", "compile", "fit", "evaluate", "print", "softmax", "figure", "subplot", "plot", "plot", "legend", "title", "subplot", "plot", "plot", "legend", "title", "show", "summary", "plot_model", "seed", "set_seed", "from_pretrained", "from_pretrained", "CustomModel", "compile_model", "train_test_split", "prepare_data", "prepare_data", "train_model", "evaluate_model", "prepare_data", "predict", "enumerate", "plot_training_history", "summarize_model", "main", "__init__", "encode_plus", "append", "append", "append", "convert_to_tensor", "convert_to_tensor", "convert_to_tensor", "model", "print", "super", "max", "argmax"], "strings": ["__main__", "accuracy", "input_ids", "attention_mask", "loss", "val_loss", "accuracy", "val_accuracy", "Training Loss", "Validation Loss", "Training and Validation Losses", "Training Accuracy", "Validation Accuracy", "Training and Validation Accuracies", "model.png", "bert-base-uncased", "bert-base-uncased", "This product is very good!", "This service is terrible.", "This product is great!", "This service is terrible.", "max_length", "tf", "Model Accuracy: ", "%", "input_ids", "attention_mask", "input_ids", "attention_mask", "from_logits", "lr", "loss", "optimizer", "metrics", "epochs", "validation_data", "axis", "figsize", "label", "label", "label", "label", "to_file", "num_labels", "transformer_model", "learning_rate", "test_size", "random_state", "epochs", "The sentiment for the text '", "' is ", " with a confidence of ", ".", "truncation", "add_special_tokens", "max_length", "padding", "return_attention_mask", "return_tensors", "input_ids", "attention_mask", "positive", "negative"]}