{"imports": ["tensorflow", "Adam", "plot_model", "MirroredStrategy", "TFBertForSequenceClassification", "BertTokenizer", "numpy"], "function_calls": ["encode_plus", "numpy", "from_pretrained", "from_pretrained", "CustomModel", "MirroredStrategy", "print", "main", "__init__", "transformer_model", "array", "array", "reshape", "reshape", "scope", "compile", "softmax", "Adam", "super", "predict"], "strings": ["__main__", "tf", "input_ids", "attention_mask", "bert-base-uncased", "bert-base-uncased", "Number of devices: ", "add_special_tokens", "max_length", "pad_to_max_length", "return_attention_mask", "return_tensors", "transformer_model", "input_ids", "attention_mask", "optimizer", "axis", "learning_rate"]}