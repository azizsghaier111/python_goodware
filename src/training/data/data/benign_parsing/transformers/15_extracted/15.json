{"imports": ["torch", "GPT2LMHeadModel", "GPT2Tokenizer", "pipeline", "pytorch_lightning"], "function_calls": ["from_pretrained", "from_pretrained", "pipeline", "tokenize", "convert_tokens_to_ids", "convert_ids_to_tokens", "tensor", "tensor", "tokenize_text", "print", "convert_token_to_id", "print", "convert_id_to_tokens", "print", "generate_text", "print", "text_completion", "print", "text_simplification", "print", "no_grad", "generate", "no_grad", "model", "encode", "encode", "simplification_pipeline"], "strings": ["gpt2", "gpt2", "text2text-generation", "google/t5-v1_1-large", "\n    Function for tokenization\n    ", "\n    Function for converting tokens to ids\n    ", "\n    Function for converting token ids to tokens\n    ", "\n    Function for text generation\n    ", "\n    Function for text completion\n    ", "\n    Function for text simplification using T5 \n    ", "__main__", "The sky is ", "generated_text", "Tokens from text: ", "Token Ids: ", "Tokens from Ids: ", "Generated text: ", "Completed text: ", "Simplified text: ", "task", "model", "max_length", "num_return_sequences"]}