{"imports": ["torch", "AutoModelForSeq2SeqLM", "AutoTokenizer", "AutoModelForQuestionAnswering", "BertForMaskedLM", "BertTokenizer", "TextDataset", "DataCollatorForLanguageModeling", "T5Tokenizer", "T5ForConditionalGeneration", "MarianMTModel", "MarianTokenizer", "detect", "Dataset", "pytorch_lightning", "DataLoader"], "function_calls": ["encode", "generate", "decode", "detect", "from_pretrained", "from_pretrained", "summarizer", "print", "TextDataset", "DataCollatorForLanguageModeling", "len", "data_collator", "__init__", "CustomDataset", "CustomDataset", "CustomDataset", "DataLoader", "DataLoader", "DataLoader", "super", "get_detection_lang"], "strings": ["__main__", "Hello, I am the text for language detection.", "pt", "t5-base", "t5-base", "I am the input text I want to summarize", "summarize: ", "The detected language is: ", "return_tensors", "max_length", "truncation", "max_length", "min_length", "length_penalty", "num_beams", "early_stopping", "tokenizer", "file_path", "block_size", "tokenizer", "mlm", "mlm_probability", "batch_size", "batch_size", "batch_size"]}