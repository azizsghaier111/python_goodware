{"imports": ["torch", "GPT2LMHeadModel", "GPT2Tokenizer", "pipeline", "BertForMaskedLM", "BertTokenizer", "TextClassificationPipeline", "TFAutoModelForSequenceClassification", "AutoTokenizer", "pipeline", "AutoModelForSeq2SeqLM", "tensorflow", "pytorch_lightning", "detect"], "function_calls": ["from_pretrained", "from_pretrained", "from_pretrained", "from_pretrained", "pipeline", "from_pretrained", "from_pretrained", "pipeline", "from_pretrained", "from_pretrained", "pipeline", "detect", "qna_pipeline", "mlm_pipeline", "tokenize", "convert_tokens_to_ids", "convert_ids_to_tokens", "tensor", "detect_language", "print", "answer_question", "print", "analyze_sentiment", "print", "masked_language_modeling", "print", "generate_text", "print", "sentiment_pipeline", "no_grad", "generate", "encode"], "strings": ["gpt2", "gpt2", "valhalla/t5-small-qa-qg-hl", "valhalla/t5-small-qa-qg-hl", "question-answering", "distilbert-base-uncased-finetuned-sst-2-english", "distilbert-base-uncased-finetuned-sst-2-english", "sentiment-analysis", "bert-base-uncased", "bert-base-uncased", "fill-mask", "__main__", "The sky is ", "The sky's color is blue due to Rayleigh scattering.", "Why is the sky blue?", "Language Detection: ", "Question Answering: ", "Sentiment Analysis: ", "The sky is [MASK].", "Masked Language Model: ", "Generated text: ", "model", "tokenizer", "model", "tokenizer", "model", "tokenizer", "question", "context", "max_length", "num_return_sequences"]}