{"imports": ["torch", "AutoModelForSequenceClassification", "AdamW", "BertConfig", "BertForMaskedLM", "BertTokenizer", "get_linear_schedule_with_warmup", "numpy", "train_test_split", "f1_score", "pad_sequences", "TensorDataset", "DataLoader", "RandomSampler", "SequentialSampler", "time", "datetime"], "function_calls": ["from_pretrained", "from_pretrained", "from_pretrained", "from_pretrained", "print", "prepare_masked_text", "predict_masked_entity", "print", "answer_question", "print", "print", "model_feat", "tokenize", "index", "index", "encode", "encode", "model_que", "argmax", "argmax", "convert_ids_to_tokens", "range", "lower", "no_grad", "len", "tensor", "tensor", "model"], "strings": ["bert-base-uncased", "The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.", "What is the Eiffel Tower?", "bert-large-uncased-whole-word-masking-finetuned-squad", "Hidden States : ", "The capital of France is [MASK].", "Predicted Entity: ", "Question: ", "Answer: ", "[mask]", "[MASK]", "pt", " [SEP]", "num_labels", "output_hidden_states", "##", " ", "return_tensors", " [SEP] ", "token_type_ids", "[CLS] "]}