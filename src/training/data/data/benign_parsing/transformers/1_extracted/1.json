{"imports": ["torch", "GPT2LMHeadModel", "GPT2Tokenizer", "pipeline", "BertForMaskedLM", "BertTokenizer", "TextClassificationPipeline", "TFAutoModelForSequenceClassification", "tensorflow", "pytorch_lightning"], "function_calls": ["from_pretrained", "from_pretrained", "from_pretrained", "from_pretrained", "TextClassificationPipeline", "from_pretrained", "from_pretrained", "pipeline", "sentiment_pipeline", "chatbot", "tokenize", "convert_tokens_to_ids", "convert_ids_to_tokens", "tensor", "tensor", "tokenize_text", "print", "convert_token_to_id", "print", "convert_id_to_tokens", "print", "generate_text", "print", "text_completion", "print", "analyze_sentiment", "print", "masked_language_modeling", "print", "no_grad", "generate", "no_grad", "gpt2_model", "encode", "encode"], "strings": ["gpt2", "gpt2", "distilbert-base-uncased-finetuned-sst-2-english", "distilbert-base-uncased-finetuned-sst-2-english", "bert-base-uncased", "bert-base-uncased", "text-generation", "\n    Function for sentiment analysis\n    ", "\n    Function for masked language modeling\n    ", "\n    Function for tokenization\n    ", "\n    Function for converting tokens to ids\n    ", "\n    Function for converting token ids to tokens\n    ", "\n    Function for text generation\n    ", "\n    Function for text completion\n    ", "__main__", "The sky is ", "Tokens from text: ", "Token Ids: ", "Tokens from Ids: ", "Generated text: ", "Completed text: ", "Sentiment Analysis: ", "The sky is [MASK].", "Masked Language Model: ", "model", "tokenizer", "model", "tokenizer", "max_length", "num_return_sequences"]}