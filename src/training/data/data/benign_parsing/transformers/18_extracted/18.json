{"imports": ["torch", "GPT2LMHeadModel", "GPT2Tokenizer", "T5Tokenizer", "T5ForConditionalGeneration", "pipeline"], "function_calls": ["from_pretrained", "from_pretrained", "from_pretrained", "from_pretrained", "pipeline", "mask_filling", "tokenize", "convert_tokens_to_ids", "convert_ids_to_tokens", "tensor", "encode", "tokenize_text", "print", "convert_token_to_id", "print", "convert_id_to_tokens", "print", "generate_text", "print", "text_simplification", "print", "mask_fill", "print", "no_grad", "generate", "no_grad", "generate", "replace", "encode"], "strings": ["gpt2", "gpt2", "google/t5-v1_1-large", "google/t5-v1_1-large", "fill-mask", "distilroberta-base", "distilroberta-base", "\n    Function for mask filling\n    ", "\n    Function for tokenization\n    ", "\n    Function for converting tokens to ids\n    ", "\n    Function for converting token ids to tokens\n    ", "\n    Function for text generation\n    ", "\n    Function for text simplification using T5 \n    ", "__main__", "The sky is blue but the earth is round", "pt", "Tokens from text: ", "Token Ids: ", "Tokens from Ids: ", "Generated text: ", "Simplified text: ", "Mask filled text: ", "model", "tokenizer", "simplify: ", "blue", "<mask>", "return_tensors", "max_length", "num_return_sequences", "max_length", "num_return_sequences"]}